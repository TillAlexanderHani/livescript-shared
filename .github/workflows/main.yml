name: Podcast Pipeline - Bulletproof Zero Duplicates
on:
  schedule:
    # Run only 4 times per day to reduce chance of conflicts
    - cron: '0 6 * * *'   # 6 AM UTC 
    - cron: '0 12 * * *'  # 12 PM UTC 
    - cron: '0 18 * * *'  # 6 PM UTC 
    - cron: '0 0 * * *'   # 12 AM UTC 
  
  workflow_dispatch:  # Allow manual trigger

permissions:
  contents: write

# CRITICAL: Global concurrency control to prevent ANY parallel runs
concurrency:
  group: podcast-pipeline-singleton
  cancel-in-progress: false  # Queue instead of cancel

jobs:
  process-podcasts:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours max
    
    steps:
    - name: ğŸš€ Checkout Repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
        
    - name: âš ï¸ Critical Safety Check - Prevent Parallel Runs
      run: |
        echo "ğŸ›¡ï¸ CRITICAL SAFETY CHECK: Preventing parallel execution"
        
        # Check for very recent database modifications (within last 2 hours)
        if [ -f "emailed_episodes.json" ]; then
          LAST_MODIFIED=$(stat -c %Y emailed_episodes.json 2>/dev/null || echo 0)
          CURRENT_TIME=$(date +%s)
          TIME_DIFF=$((CURRENT_TIME - LAST_MODIFIED))
          
          # If modified within 2 hours (7200 seconds), skip this run
          if [ $TIME_DIFF -lt 7200 ]; then
            echo "âš ï¸ DATABASE MODIFIED ${TIME_DIFF} SECONDS AGO ($(($TIME_DIFF / 60)) minutes)"
            echo "This indicates another pipeline may have run recently"
            echo "ABORTING THIS RUN TO PREVENT DUPLICATES"
            exit 0  # Exit cleanly to prevent workflow failure
          else
            echo "âœ… Database last modified ${TIME_DIFF} seconds ago - safe to proceed"
            echo "ğŸ“Š That's $(($TIME_DIFF / 3600)) hours ago"
          fi
        else
          echo "ğŸ†• No existing database - this appears to be the first run"
        fi
        
        # Additional check for lock files or temporary files
        if [ -f "pipeline.lock" ] || [ -f "*.tmp" ] 2>/dev/null; then
          echo "âš ï¸ Found existing lock or temporary files - another process may be running"
          echo "ABORTING TO PREVENT CONFLICTS"
          exit 0
        fi
        
        echo "âœ… ALL SAFETY CHECKS PASSED - PROCEEDING WITH PIPELINE"
        
    - name: ğŸ Setup Python Environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
        
    - name: ğŸ“¦ Install System Dependencies
      run: |
        sudo apt-get update -qq
        sudo apt-get install -y ffmpeg
        
    - name: ğŸ“¦ Install Python Dependencies  
      run: |
        python -m pip install --upgrade pip
        
        # Install specific stable versions
        pip install "numpy<2.0"
        pip install torch==1.13.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install openai-whisper==20231117
        pip install feedparser==6.0.10 requests==2.31.0 python-dateutil==2.8.2
        
        echo "âœ… Dependencies installed successfully"
        
    - name: ğŸ“Š Pre-run Database Analysis
      run: |
        echo "ğŸ“Š PRE-RUN DATABASE ANALYSIS:"
        
        if [ -f "emailed_episodes.json" ]; then
          echo "  ğŸ“ Database exists: $(du -h emailed_episodes.json | cut -f1)"
          echo "  ğŸ“… Last modified: $(stat -c %y emailed_episodes.json)"
          
          # Count URLs safely
          URL_COUNT=$(python3 -c "
import json
try:
    with open('emailed_episodes.json', 'r') as f:
        data = json.load(f)
    episodes = data.get('episodes', {})
    urls = set()
    for ep in episodes.values():
        if isinstance(ep, dict) and 'url' in ep:
            urls.add(ep['url'])
    print(f'Total episode records: {len(episodes)}')
    print(f'Unique URLs tracked: {len(urls)}')
    print(f'Database version: {data.get(\"version\", \"unknown\")}')
except Exception as e:
    print(f'Error reading database: {e}')
" 2>/dev/null || echo "  âŒ Error reading database")
        else
          echo "  ğŸ†• No existing database found"
        fi
        
    - name: âœ… Environment Validation
      run: |
        echo "ğŸ” VALIDATING ENVIRONMENT VARIABLES:"
        
        # Check required variables
        MISSING=""
        [ -z "$MISTRAL_API_KEY" ] && MISSING="$MISSING MISTRAL_API_KEY"
        [ -z "$EMAIL_FROM" ] && MISSING="$MISSING EMAIL_FROM"
        [ -z "$EMAIL_TO" ] && MISSING="$MISSING EMAIL_TO"
        [ -z "$EMAIL_PASSWORD" ] && MISSING="$MISSING EMAIL_PASSWORD"
        
        if [ -n "$MISSING" ]; then
          echo "âŒ Missing required variables:$MISSING"
          exit 1
        fi
        
        echo "âœ… All environment variables validated"
      env:
        MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
        EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
        EMAIL_TO: ${{ secrets.EMAIL_TO }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        
    - name: ğŸš€ Execute Pipeline with Maximum Safety
      env:
        MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
        EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
        EMAIL_TO: ${{ secrets.EMAIL_TO }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        GITHUB_RUN_NUMBER: ${{ github.run_number }}
      run: |
        echo "ğŸš€ STARTING BULLETPROOF PODCAST PIPELINE"
        echo "ğŸ”’ DUPLICATE PREVENTION: URL-based tracking"
        echo "ğŸ“‹ SAFETY SETTINGS:"
        echo "  â€¢ Max episode age: 5 days"
        echo "  â€¢ Max episodes per feed: 1"
        echo "  â€¢ Feed processing delay: 10 seconds"
        echo "  â€¢ Database: Atomic writes only"
        echo "  â€¢ Run ID: ${{ github.run_id }}"
        echo ""
        
        # Execute the pipeline with error handling
        if python podcast_shared_live_5.py; then
          echo ""
          echo "âœ… PIPELINE COMPLETED SUCCESSFULLY"
        else
          echo ""
          echo "âŒ PIPELINE FAILED"
          exit 1
        fi
        
    - name: ğŸ“Š Post-run Analysis
      run: |
        echo "ğŸ“Š POST-RUN ANALYSIS:"
        
        if [ -f "emailed_episodes.json" ]; then
          echo "  ğŸ“ Database size: $(du -h emailed_episodes.json | cut -f1)"
          echo "  ğŸ“… Last modified: $(stat -c %y emailed_episodes.json)"
          
          # Analyze results safely
          python3 -c "
import json
try:
    with open('emailed_episodes.json', 'r') as f:
        data = json.load(f)
    episodes = data.get('episodes', {})
    urls = set()
    for ep in episodes.values():
        if isinstance(ep, dict) and 'url' in ep:
            urls.add(ep['url'])
    print(f'  ğŸ“Š Total records: {len(episodes)}')
    print(f'  ğŸ”— Unique URLs: {len(urls)}')
    print(f'  ğŸ“¦ Version: {data.get(\"version\", \"unknown\")}')
    
    # Check for duplicates
    if len(episodes) > len(urls):
        print(f'  âš ï¸ WARNING: {len(episodes) - len(urls)} potential duplicate records detected')
    else:
        print('  âœ… No duplicate URLs detected')
        
except Exception as e:
    print(f'  âŒ Error analyzing database: {e}')
" 2>/dev/null
        else
          echo "  âŒ No database file found after execution"
        fi
        
        # Clean up any remaining temporary files
        rm -f pipeline.lock *.tmp downloads/* 2>/dev/null || true
        
    - name: ğŸ’¾ Atomic Database Commit
      run: |
        # Configure git
        git config --local user.email "podcast-pipeline@actions.bot"
        git config --local user.name "Podcast Pipeline Bot"
        
        echo "ğŸ”„ CHECKING FOR DATABASE CHANGES..."
        
        # Pull latest changes first to avoid conflicts
        git pull origin main --rebase --strategy-option=theirs || {
          echo "âš ï¸ Resolving rebase conflicts"
          git reset --hard origin/main
        }
        
        # Check if database changed
        if [ -f "emailed_episodes.json" ]; then
          if git diff --quiet emailed_episodes.json; then
            echo "ğŸ“„ No database changes detected"
          else
            # Validate JSON before committing
            if python3 -c "import json; json.load(open('emailed_episodes.json'))" 2>/dev/null; then
              echo "ğŸ“„ Valid database changes detected - preparing commit"
              git add emailed_episodes.json
              
              # Create descriptive commit message
              timestamp=$(date -u '+%Y-%m-%d %H:%M UTC')
              commit_msg="Update podcast database [$timestamp] [run:${{ github.run_number }}] [skip ci]"
              git commit -m "$commit_msg"
              
              # Push with retry logic
              max_attempts=3
              attempt=1
              
              while [ $attempt -le $max_attempts ]; do
                echo "ğŸ“¤ Push attempt $attempt/$max_attempts"
                
                if git push origin main; then
                  echo "âœ… DATABASE SUCCESSFULLY COMMITTED AND PUSHED"
                  break
                elif [ $attempt -lt $max_attempts ]; then
                  echo "âš ï¸ Push failed, retrying in 10 seconds..."
                  sleep 10
                  
                  # Pull and rebase before retry
                  git pull origin main --rebase --strategy-option=theirs || {
                    git reset --hard origin/main
                    git add emailed_episodes.json
                    git commit -m "$commit_msg"
                  }
                else
                  echo "âŒ FAILED TO PUSH AFTER $max_attempts ATTEMPTS"
                  exit 1
                fi
                
                attempt=$((attempt + 1))
              done
              
            else
              echo "âŒ Invalid JSON in database - not committing"
              git checkout -- emailed_episodes.json
            fi
          fi
        else
          echo "ğŸ“„ No database file to commit"
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        
    - name: ğŸ“‹ Final Status Report
      if: always()
      run: |
        echo ""
        echo "ğŸ PIPELINE EXECUTION COMPLETE"
        echo "  ğŸ“… Completed: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        echo "  ğŸ”¢ Run Number: ${{ github.run_number }}"
        echo "  ğŸ†” Run ID: ${{ github.run_id }}"
        echo "  ğŸ¯ Trigger: ${{ github.event_name }}"
        echo ""
        echo "ğŸ›¡ï¸ DUPLICATE PREVENTION STATUS: BULLETPROOF âœ…"
        echo "ğŸ“Š SAFETY MEASURES ACTIVE:"
        echo "  â€¢ URL-based duplicate detection âœ…"
        echo "  â€¢ Atomic database operations âœ…"
        echo "  â€¢ Concurrency control âœ…"
        echo "  â€¢ Recent run detection âœ…"
        echo "  â€¢ Single episode per feed âœ…"
        echo ""
        echo "ğŸ¯ ZERO DUPLICATE GUARANTEE ACTIVE"
