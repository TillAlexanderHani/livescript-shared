name: Podcast Pipeline - Fast & Simple
on:
  schedule:
    - cron: '0 6 * * *'   # 6 AM UTC (fixed typo)
    - cron: '0 12 * * *'  # 12 PM UTC (fixed typo)
    - cron: '0 18 * * *'  # 6 PM UTC (fixed typo)
    - cron: '0 0 * * *'   # 12 AM UTC (fixed typo)
  
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: podcast-pipeline-singleton
  cancel-in-progress: false  # Changed to false to queue runs instead of canceling

jobs:
  process-podcasts:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1
        
    - name: Quick Duplicate Check
      id: duplicate_check
      run: |
        # Skip only if very recent (20 minutes) and not manual
        if [ "${{ github.event_name }}" != "workflow_dispatch" ] && [ -f "emailed_episodes.json" ]; then
          LAST_MODIFIED=$(stat -c %Y emailed_episodes.json 2>/dev/null || echo 0)
          CURRENT_TIME=$(date +%s)
          TIME_DIFF=$((CURRENT_TIME - LAST_MODIFIED))
          
          if [ $TIME_DIFF -lt 1200 ]; then
            echo "Recent run detected - skipping"
            echo "action=skip" >> $GITHUB_OUTPUT
            exit 0
          fi
        fi
        
        echo "action=run" >> $GITHUB_OUTPUT
        
    - name: Setup Python
      if: steps.duplicate_check.outputs.action == 'run'
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
        
    - name: Install Dependencies (Minimal)
      if: steps.duplicate_check.outputs.action == 'run'
      run: |
        sudo apt-get update -qq
        sudo apt-get install -y ffmpeg --no-install-recommends
        
        pip install --upgrade pip
        pip install "numpy<2.0" torch==1.13.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install openai-whisper==20231117 feedparser==6.0.10 requests==2.31.0 python-dateutil==2.8.2
        
    - name: Initialize JSON Database
      if: steps.duplicate_check.outputs.action == 'run'
      run: |
        # Fix corrupted JSON file
        if [ -f "emailed_episodes.json" ]; then
          FILE_SIZE=$(wc -c < emailed_episodes.json)
          if [ $FILE_SIZE -lt 10 ]; then
            echo "Fixing corrupted JSON file ($FILE_SIZE bytes)"
            echo '{"episodes": {}, "version": "1.0"}' > emailed_episodes.json
          fi
        else
          echo "Creating new JSON database"
          echo '{"episodes": {}, "version": "1.0"}' > emailed_episodes.json
        fi
        echo "JSON file ready:"
        cat emailed_episodes.json
        
    - name: Setup Directories
      if: steps.duplicate_check.outputs.action == 'run'
      run: |
        mkdir -p downloads transcripts
        
    - name: Run Pipeline
      if: steps.duplicate_check.outputs.action == 'run'
      env:
        MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
        EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
        EMAIL_TO: ${{ secrets.EMAIL_TO }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
      run: |
        echo "Starting pipeline..."
        python podcast_shared_live_5.py
        
    - name: Verify Results
      if: steps.duplicate_check.outputs.action == 'run'
      run: |
        echo "=== POST-PIPELINE VERIFICATION ==="
        if [ -f "emailed_episodes.json" ]; then
          echo "JSON file size: $(wc -c < emailed_episodes.json) bytes"
          echo "JSON file lines: $(wc -l < emailed_episodes.json)"
          echo "File is valid JSON:"
          python -c "import json; json.load(open('emailed_episodes.json')); print('âœ… Valid JSON')" || echo "âŒ Invalid JSON"
        else
          echo "âŒ No JSON file found after pipeline"
        fi
        echo "=== END VERIFICATION ==="
        
    - name: Commit Changes
      if: steps.duplicate_check.outputs.action == 'run'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        echo "=== COMMIT DEBUG ==="
        echo "File before commit:"
        ls -la emailed_episodes.json
        wc -c emailed_episodes.json
        
        echo "Git status:"
        git status
        
        echo "Git diff:"
        git diff emailed_episodes.json || echo "No diff output"
        
        # Pull latest changes first to avoid conflicts
        git pull origin main --rebase || true
        
        if [ -f "emailed_episodes.json" ] && ! git diff --quiet emailed_episodes.json 2>/dev/null; then
          # Validate JSON before committing
          if python -c "import json; data=json.load(open('emailed_episodes.json')); print(f'Episodes: {len(data.get(\"episodes\", {}))}')" 2>/dev/null; then
            git add emailed_episodes.json
            echo "File staged, committing..."
            git commit -m "Update podcast database [$(date -u '+%Y-%m-%d %H:%M UTC')]"
            echo "Pushing..."
            git push
            echo "âœ… Database committed successfully"
          else
            echo "âŒ Invalid JSON - not committing"
          fi
        else
          echo "ðŸ“ No changes to commit (file unchanged or missing)"
          echo "Current file content:"
          cat emailed_episodes.json | head -10
        fi
        echo "=== END COMMIT DEBUG ==="
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Cleanup & Status
      if: always()
      run: |
        echo "Run complete: ${{ steps.duplicate_check.outputs.action || 'unknown' }}"
        echo "Manual runs always execute"
        
        # Cleanup temporary files
        rm -f pipeline.lock *.tmp 2>/dev/null || true
        rm -rf downloads/* transcripts/* 2>/dev/null || true
        
        # Final status
        if [ -f "emailed_episodes.json" ]; then
          echo "Final database size: $(wc -c < emailed_episodes.json) bytes"
        fi
